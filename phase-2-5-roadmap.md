# ðŸš€ PHASE 2-5 IMPLEMENTATION ROADMAP
## Avalanche Disaster Relief Network - Complete Development Plan

### ðŸ“Š Current Status Analysis

Based on the PHASE-1.md implementation, you have successfully completed the **frontend foundation** with:

âœ… **COMPLETED (PHASE 1)**:
- React + Vite responsive web application
- Complete admin dashboard with 6 functional tabs
- Web3 integration with Zustand state management
- Pinata IPFS service configuration
- Beautiful UI components with Tailwind CSS
- Real-time data visualization components
- PWA setup with service worker

âŒ **PENDING CRITICAL COMPONENTS**:
- Avalanche CLI and subnet deployment
- Smart contract development and deployment  
- Backend API services
- Database and caching layer
- Real-time monitoring system
- Advanced integrations and security

---

## ðŸŽ¯ PHASE 2: Avalanche Infrastructure & Smart Contracts
**Duration**: 5-7 hours | **Priority**: CRITICAL | **Timeline**: Aug 9-16, 2025

### ðŸ”§ Task 1: Avalanche CLI & Subnet Setup (2 Hours)

#### Day 1: Environment Setup
```bash
# Install Avalanche CLI
curl -sSfL https://raw.githubusercontent.com/ava-labs/avalanche-cli/main/scripts/install.sh | sh -s
export PATH=~/bin:$PATH

# Verify installation
avalanche --version
```

#### Subnet Creation & Configuration
```bash
# Create disaster relief subnet
avalanche subnet create disaster-relief-network

# Configuration prompts:
# VM: Subnet-EVM
# ChainID: 2025090801 (unique identifier)
# Token Symbol: DREL (Disaster Relief Token)  
# Gas Configuration: Use latest version
# Airdrop: 1 million tokens to default address

# Deploy to local network first
avalanche subnet deploy disaster-relief-network --local

# Deploy to Fuji testnet
avalanche subnet deploy disaster-relief-network --fuji
```

#### Subnet Configuration File
```json
{
  "name": "disaster-relief-network",
  "vm": "Subnet-EVM", 
  "chainId": 2025090801,
  "token": {
    "name": "Disaster Relief Token",
    "symbol": "DREL",
    "decimals": 18
  },
  "gasConfig": {
    "gasLimit": 15000000,
    "targetGas": 100000000,
    "baseFee": 1000000000,
    "targetGasRate": 2
  },
  "feeConfig": {
    "gasPrice": 1000000000,
    "minGasPrice": 1000000000
  }
}
```

### ðŸ”§ Task 2: Smart Contract Development (3 days)

#### Day 1: Foundry Setup & Base Contracts
```bash
# Install Foundry
curl -L https://foundry.paradigm.xyz | bash
foundryup

# Initialize project
forge init disaster-relief-contracts
cd disaster-relief-contracts
```

#### Foundry Configuration
```toml
# foundry.toml
[profile.default]
src = "src"
out = "out"
libs = ["lib"]
solc = "0.8.19"
optimizer = true
optimizer_runs = 200

[rpc_endpoints]
fuji = "https://api.avax-test.network/ext/bc/C/rpc"
disaster-relief = "http://localhost:9650/ext/bc/YOUR_SUBNET_ID/rpc"

[etherscan]
avalanche = { key = "${SNOWTRACE_API_KEY}" }
```

#### Smart Contract Implementation
```solidity
// src/DisasterReliefSystem.sol
pragma solidity ^0.8.19;

import "@openzeppelin/contracts/security/ReentrancyGuard.sol";
import "@openzeppelin/contracts/access/AccessControl.sol";
import "@openzeppelin/contracts/token/ERC20/IERC20.sol";

contract DisasterReliefSystem is ReentrancyGuard, AccessControl {
    bytes32 public constant ADMIN_ROLE = keccak256("ADMIN_ROLE");
    bytes32 public constant VENDOR_ROLE = keccak256("VENDOR_ROLE");
    
    IERC20 public immutable usdcToken;
    
    struct DisasterZone {
        string name;
        int256 latitude;
        int256 longitude; 
        uint256 radius;
        bool active;
        uint256 createdAt;
        uint256 totalFunding;
        uint256 totalSpent;
    }
    
    struct Vendor {
        address vendorAddress;
        string name;
        string location;
        uint256 disasterZoneId;
        bool verified;
        uint256 totalRedeemed;
        uint256 transactionCount;
        string ipfsKycHash;
    }
    
    struct Voucher {
        address beneficiary;
        uint256 amount;
        uint256 disasterZoneId;
        uint256 expiryTime;
        bool used;
        string[] allowedCategories;
        uint256 createdAt;
    }
    
    struct ProofOfAid {
        uint256 voucherId;
        address vendor;
        string ipfsHash;
        int256 transactionLat;
        int256 transactionLng;
        uint256 timestamp;
        string category;
        uint256 amount;
    }
    
    // Mappings
    mapping(uint256 => DisasterZone) public disasterZones;
    mapping(address => Vendor) public vendors;
    mapping(uint256 => Voucher) public vouchers;
    mapping(uint256 => ProofOfAid) public proofOfAids;
    mapping(uint256 => address[]) public zoneVendors;
    mapping(address => uint256[]) public userVouchers;
    
    // Counters
    uint256 public disasterZoneCounter;
    uint256 public voucherCounter;
    uint256 public proofCounter;
    
    // Events
    event DisasterZoneCreated(uint256 indexed zoneId, string name, uint256 funding);
    event VendorRegistered(address indexed vendor, uint256 indexed zoneId, string ipfsKycHash);
    event VoucherIssued(address indexed beneficiary, uint256 amount, uint256 voucherId);
    event VoucherRedeemed(address indexed vendor, uint256 indexed voucherId, uint256 amount);
    event ProofOfAidSubmitted(uint256 indexed proofId, uint256 indexed voucherId, string ipfsHash);
    event FundsDeposited(uint256 indexed zoneId, uint256 amount, address depositor);
    
    constructor(address _usdcToken) {
        usdcToken = IERC20(_usdcToken);
        _grantRole(DEFAULT_ADMIN_ROLE, msg.sender);
        _grantRole(ADMIN_ROLE, msg.sender);
    }
    
    // Core Functions
    function createDisasterZone(
        string memory _name,
        int256 _latitude,
        int256 _longitude,
        uint256 _radius,
        uint256 _initialFunding
    ) external onlyRole(ADMIN_ROLE) returns (uint256) {
        uint256 zoneId = disasterZoneCounter++;
        
        disasterZones[zoneId] = DisasterZone({
            name: _name,
            latitude: _latitude,
            longitude: _longitude,
            radius: _radius,
            active: true,
            createdAt: block.timestamp,
            totalFunding: _initialFunding,
            totalSpent: 0
        });
        
        if (_initialFunding > 0) {
            require(
                usdcToken.transferFrom(msg.sender, address(this), _initialFunding),
                "USDC transfer failed"
            );
            emit FundsDeposited(zoneId, _initialFunding, msg.sender);
        }
        
        emit DisasterZoneCreated(zoneId, _name, _initialFunding);
        return zoneId;
    }
    
    function registerVendor(
        address _vendorAddress,
        string memory _name,
        string memory _location,
        uint256 _disasterZoneId,
        string memory _ipfsKycHash
    ) external onlyRole(ADMIN_ROLE) {
        require(disasterZones[_disasterZoneId].active, "Disaster zone not active");
        require(vendors[_vendorAddress].vendorAddress == address(0), "Vendor already registered");
        
        vendors[_vendorAddress] = Vendor({
            vendorAddress: _vendorAddress,
            name: _name,
            location: _location,
            disasterZoneId: _disasterZoneId,
            verified: true,
            totalRedeemed: 0,
            transactionCount: 0,
            ipfsKycHash: _ipfsKycHash
        });
        
        zoneVendors[_disasterZoneId].push(_vendorAddress);
        _grantRole(VENDOR_ROLE, _vendorAddress);
        
        emit VendorRegistered(_vendorAddress, _disasterZoneId, _ipfsKycHash);
    }
    
    function issueVoucher(
        address _beneficiary,
        uint256 _amount,
        uint256 _disasterZoneId,
        uint256 _expiryDays,
        string[] memory _allowedCategories
    ) external onlyRole(ADMIN_ROLE) returns (uint256) {
        require(disasterZones[_disasterZoneId].active, "Disaster zone not active");
        require(_amount > 0, "Amount must be greater than 0");
        require(
            disasterZones[_disasterZoneId].totalFunding >= 
            disasterZones[_disasterZoneId].totalSpent + _amount,
            "Insufficient funds in disaster zone"
        );
        
        uint256 voucherId = voucherCounter++;
        
        vouchers[voucherId] = Voucher({
            beneficiary: _beneficiary,
            amount: _amount,
            disasterZoneId: _disasterZoneId,
            expiryTime: block.timestamp + (_expiryDays * 1 days),
            used: false,
            allowedCategories: _allowedCategories,
            createdAt: block.timestamp
        });
        
        userVouchers[_beneficiary].push(voucherId);
        
        emit VoucherIssued(_beneficiary, _amount, voucherId);
        return voucherId;
    }
    
    function redeemVoucher(
        uint256 _voucherId,
        uint256 _amount,
        string memory _ipfsHash,
        int256 _transactionLat,
        int256 _transactionLng,
        string memory _category
    ) external onlyRole(VENDOR_ROLE) nonReentrant {
        Voucher storage voucher = vouchers[_voucherId];
        require(!voucher.used, "Voucher already used");
        require(block.timestamp <= voucher.expiryTime, "Voucher expired");
        require(_amount <= voucher.amount, "Amount exceeds voucher value");
        require(vendors[msg.sender].verified, "Vendor not verified");
        
        // Verify vendor is in the same disaster zone
        require(
            vendors[msg.sender].disasterZoneId == voucher.disasterZoneId,
            "Vendor not authorized for this disaster zone"
        );
        
        // Verify location is within disaster zone
        require(
            _isWithinDisasterZone(_transactionLat, _transactionLng, voucher.disasterZoneId),
            "Transaction outside disaster zone"
        );
        
        // Verify category is allowed
        require(_isCategoryAllowed(_category, voucher.allowedCategories), "Category not allowed");
        
        // Update voucher and vendor data
        voucher.used = true;
        vendors[msg.sender].totalRedeemed += _amount;
        vendors[msg.sender].transactionCount++;
        disasterZones[voucher.disasterZoneId].totalSpent += _amount;
        
        // Create proof of aid record
        uint256 proofId = proofCounter++;
        proofOfAids[proofId] = ProofOfAid({
            voucherId: _voucherId,
            vendor: msg.sender,
            ipfsHash: _ipfsHash,
            transactionLat: _transactionLat,
            transactionLng: _transactionLng,
            timestamp: block.timestamp,
            category: _category,
            amount: _amount
        });
        
        // Transfer USDC to vendor
        require(usdcToken.transfer(msg.sender, _amount), "USDC transfer failed");
        
        emit VoucherRedeemed(msg.sender, _voucherId, _amount);
        emit ProofOfAidSubmitted(proofId, _voucherId, _ipfsHash);
    }
    
    // Helper Functions
    function _isWithinDisasterZone(
        int256 _lat,
        int256 _lng,
        uint256 _zoneId
    ) internal view returns (bool) {
        DisasterZone memory zone = disasterZones[_zoneId];
        
        // Haversine distance calculation (simplified for gas efficiency)
        int256 latDiff = _lat - zone.latitude;
        int256 lngDiff = _lng - zone.longitude;
        uint256 distanceSquared = uint256(latDiff * latDiff + lngDiff * lngDiff);
        uint256 radiusSquared = zone.radius * zone.radius;
        
        return distanceSquared <= radiusSquared;
    }
    
    function _isCategoryAllowed(
        string memory _category,
        string[] memory _allowedCategories
    ) internal pure returns (bool) {
        for (uint i = 0; i < _allowedCategories.length; i++) {
            if (keccak256(bytes(_category)) == keccak256(bytes(_allowedCategories[i]))) {
                return true;
            }
        }
        return false;
    }
    
    // View Functions
    function getDisasterZoneVendors(uint256 _zoneId) external view returns (address[] memory) {
        return zoneVendors[_zoneId];
    }
    
    function getUserVouchers(address _user) external view returns (uint256[] memory) {
        return userVouchers[_user];
    }
    
    function getDisasterZoneStats(uint256 _zoneId) external view returns (
        string memory name,
        uint256 totalFunding,
        uint256 totalSpent,
        uint256 remainingFunds,
        uint256 vendorCount,
        bool active
    ) {
        DisasterZone memory zone = disasterZones[_zoneId];
        return (
            zone.name,
            zone.totalFunding,
            zone.totalSpent,
            zone.totalFunding - zone.totalSpent,
            zoneVendors[_zoneId].length,
            zone.active
        );
    }
}
```

#### Day 2: Additional Contracts & Testing
```solidity
// src/VendorRegistry.sol - Specialized vendor management
// src/GeolocationVerifier.sol - Advanced GPS validation
// src/MockUSDC.sol - Testing token for local development
```

#### Smart Contract Testing
```solidity
// test/DisasterReliefSystem.t.sol
pragma solidity ^0.8.19;

import {Test} from "forge-std/Test.sol";
import {DisasterReliefSystem} from "../src/DisasterReliefSystem.sol";
import {MockUSDC} from "../src/MockUSDC.sol";

contract DisasterReliefSystemTest is Test {
    DisasterReliefSystem public disasterRelief;
    MockUSDC public usdc;
    
    address public admin = address(1);
    address public vendor = address(2);
    address public beneficiary = address(3);
    
    function setUp() public {
        usdc = new MockUSDC();
        disasterRelief = new DisasterReliefSystem(address(usdc));
        
        // Setup test data
        usdc.mint(admin, 1000000e6); // 1M USDC
        usdc.mint(address(disasterRelief), 500000e6); // 500K USDC
    }
    
    function testCreateDisasterZone() public {
        vm.startPrank(admin);
        usdc.approve(address(disasterRelief), 100000e6);
        
        uint256 zoneId = disasterRelief.createDisasterZone(
            "Hurricane Relief",
            25761700, // Miami latitude
            -80191700, // Miami longitude
            50000, // 50km radius
            100000e6 // 100K USDC funding
        );
        
        (string memory name, uint256 totalFunding,,,,) = disasterRelief.getDisasterZoneStats(zoneId);
        assertEq(name, "Hurricane Relief");
        assertEq(totalFunding, 100000e6);
        vm.stopPrank();
    }
    
    // Additional comprehensive tests...
}
```

#### Day 3: Deployment & Verification
```bash
# Deploy to Fuji testnet
forge script script/Deploy.s.sol --rpc-url fuji --private-key $PRIVATE_KEY --broadcast --verify

# Deploy to custom subnet
forge script script/Deploy.s.sol --rpc-url disaster-relief --private-key $PRIVATE_KEY --broadcast
```

### ðŸ”§ Task 3: Frontend-Contract Integration (2 days)

#### Update Web3 Store Configuration
```javascript
// frontend/src/store/web3Store.js
const CONTRACT_ADDRESSES = {
  DisasterReliefSystem: "0x...", // Deployed contract address
  VendorRegistry: "0x...",
  GeolocationVerifier: "0x...",
  USDC: "0x5425890298aed601595a70AB815c96711a31Bc65" // Fuji USDC
};

const DISASTER_RELIEF_SUBNET = {
  chainId: 2025090801,
  chainName: 'Disaster Relief Network',
  nativeCurrency: {
    name: 'Disaster Relief Token',
    symbol: 'DREL',
    decimals: 18,
  },
  rpcUrls: ['https://subnets.avax.network/disaster-relief/rpc'],
  blockExplorerUrls: ['https://subnets.avax.network/disaster-relief/explorer'],
};
```

#### Contract Interaction Service
```javascript
// frontend/src/services/contractService.js
import { ethers } from 'ethers';
import DisasterReliefABI from '../abis/DisasterReliefSystem.json';

export class ContractService {
  constructor(provider, signer) {
    this.provider = provider;
    this.signer = signer;
    this.contract = new ethers.Contract(
      CONTRACT_ADDRESSES.DisasterReliefSystem,
      DisasterReliefABI,
      signer
    );
  }

  async createDisasterZone(name, latitude, longitude, radius, funding) {
    try {
      const latInt = Math.floor(latitude * 1e6);
      const lngInt = Math.floor(longitude * 1e6);
      
      const tx = await this.contract.createDisasterZone(
        name,
        latInt,
        lngInt,
        radius,
        ethers.utils.parseUnits(funding.toString(), 6)
      );
      
      const receipt = await tx.wait();
      
      // Extract zone ID from events
      const event = receipt.events.find(e => e.event === 'DisasterZoneCreated');
      return {
        zoneId: event.args.zoneId.toNumber(),
        txHash: receipt.transactionHash
      };
    } catch (error) {
      throw new Error(`Failed to create disaster zone: ${error.message}`);
    }
  }

  async registerVendor(address, name, location, zoneId, kycHash) {
    try {
      const tx = await this.contract.registerVendor(
        address,
        name,
        location,
        zoneId,
        kycHash
      );
      return await tx.wait();
    } catch (error) {
      throw new Error(`Failed to register vendor: ${error.message}`);
    }
  }

  async issueVoucher(beneficiary, amount, zoneId, expiryDays, categories) {
    try {
      const tx = await this.contract.issueVoucher(
        beneficiary,
        ethers.utils.parseUnits(amount.toString(), 6),
        zoneId,
        expiryDays,
        categories
      );
      
      const receipt = await tx.wait();
      const event = receipt.events.find(e => e.event === 'VoucherIssued');
      
      return {
        voucherId: event.args.voucherId.toNumber(),
        txHash: receipt.transactionHash
      };
    } catch (error) {
      throw new Error(`Failed to issue voucher: ${error.message}`);
    }
  }

  async redeemVoucher(voucherId, amount, ipfsHash, lat, lng, category) {
    try {
      const latInt = Math.floor(lat * 1e6);
      const lngInt = Math.floor(lng * 1e6);
      
      const tx = await this.contract.redeemVoucher(
        voucherId,
        ethers.utils.parseUnits(amount.toString(), 6),
        ipfsHash,
        latInt,
        lngInt,
        category
      );
      
      return await tx.wait();
    } catch (error) {
      throw new Error(`Failed to redeem voucher: ${error.message}`);
    }
  }

  async getDisasterZoneStats(zoneId) {
    try {
      const stats = await this.contract.getDisasterZoneStats(zoneId);
      return {
        name: stats.name,
        totalFunding: ethers.utils.formatUnits(stats.totalFunding, 6),
        totalSpent: ethers.utils.formatUnits(stats.totalSpent, 6),
        remainingFunds: ethers.utils.formatUnits(stats.remainingFunds, 6),
        vendorCount: stats.vendorCount.toNumber(),
        active: stats.active
      };
    } catch (error) {
      throw new Error(`Failed to get disaster zone stats: ${error.message}`);
    }
  }

  // Event listeners for real-time updates
  onDisasterZoneCreated(callback) {
    this.contract.on('DisasterZoneCreated', (zoneId, name, funding, event) => {
      callback({
        zoneId: zoneId.toNumber(),
        name,
        funding: ethers.utils.formatUnits(funding, 6),
        txHash: event.transactionHash
      });
    });
  }

  onVoucherRedeemed(callback) {
    this.contract.on('VoucherRedeemed', (vendor, voucherId, amount, event) => {
      callback({
        vendor,
        voucherId: voucherId.toNumber(),
        amount: ethers.utils.formatUnits(amount, 6),
        txHash: event.transactionHash,
        timestamp: Date.now()
      });
    });
  }
}
```

---

## ðŸŽ¯ PHASE 3: Backend Services & API Development
**Duration**: 4-6 days | **Priority**: High | **Timeline**: Aug 17-23, 2025

### ðŸ”§ Task 1: API Server Development (3 days)

#### Project Structure Setup
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ disasters.js
â”‚   â”‚   â”œâ”€â”€ vendors.js
â”‚   â”‚   â”œâ”€â”€ transactions.js
â”‚   â”‚   â”œâ”€â”€ ipfs.js
â”‚   â”‚   â””â”€â”€ auth.js
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ .env
â”œâ”€â”€ server.js
â””â”€â”€ package.json
```

#### Express Server Setup
```javascript
// server.js
const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const rateLimit = require('express-rate-limit');
const compression = require('compression');
const morgan = require('morgan');
require('dotenv').config();

const app = express();

// Middleware
app.use(helmet());
app.use(compression());
app.use(morgan('combined'));
app.use(cors({
  origin: process.env.FRONTEND_URL || 'http://localhost:3001',
  credentials: true
}));

// Rate limiting
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100 // limit each IP to 100 requests per windowMs
});
app.use(limiter);

app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// Routes
app.use('/api/disasters', require('./src/routes/disasters'));
app.use('/api/vendors', require('./src/routes/vendors'));
app.use('/api/transactions', require('./src/routes/transactions'));
app.use('/api/ipfs', require('./src/routes/ipfs'));
app.use('/api/auth', require('./src/routes/auth'));

// Health check
app.get('/health', (req, res) => {
  res.status(200).json({
    status: 'OK',
    timestamp: new Date().toISOString(),
    uptime: process.uptime()
  });
});

// Error handling middleware
app.use((error, req, res, next) => {
  console.error('Error:', error);
  res.status(error.status || 500).json({
    error: {
      message: error.message || 'Internal Server Error',
      status: error.status || 500
    }
  });
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on port ${PORT}`);
  console.log(`ðŸŒ Frontend URL: ${process.env.FRONTEND_URL}`);
  console.log(`ðŸ“Š Environment: ${process.env.NODE_ENV}`);
});
```

#### API Route Implementation
```javascript
// src/routes/disasters.js
const express = require('express');
const router = express.Router();
const disasterController = require('../controllers/disasterController');
const auth = require('../middleware/auth');
const validate = require('../middleware/validation');

// Get all disasters
router.get('/', disasterController.getAllDisasters);

// Get disaster by ID
router.get('/:id', disasterController.getDisasterById);

// Create new disaster (admin only)
router.post('/', 
  auth.requireAdmin,
  validate.createDisaster,
  disasterController.createDisaster
);

// Update disaster status
router.patch('/:id/status',
  auth.requireAdmin,
  validate.updateDisasterStatus,
  disasterController.updateDisasterStatus
);

// Get disaster statistics
router.get('/:id/stats', disasterController.getDisasterStats);

// Get disaster transactions
router.get('/:id/transactions', disasterController.getDisasterTransactions);

module.exports = router;
```

#### Disaster Controller Implementation
```javascript
// src/controllers/disasterController.js
const blockchainService = require('../services/blockchainService');
const db = require('../services/databaseService');
const cache = require('../services/cacheService');

class DisasterController {
  async getAllDisasters(req, res) {
    try {
      const { page = 1, limit = 10, status } = req.query;
      
      // Try cache first
      const cacheKey = `disasters:${page}:${limit}:${status}`;
      let disasters = await cache.get(cacheKey);
      
      if (!disasters) {
        disasters = await db.disasters.findAll({
          where: status ? { status } : {},
          limit: parseInt(limit),
          offset: (page - 1) * limit,
          order: [['createdAt', 'DESC']]
        });
        
        // Cache for 5 minutes
        await cache.set(cacheKey, disasters, 300);
      }
      
      res.json({
        success: true,
        data: disasters,
        pagination: {
          page: parseInt(page),
          limit: parseInt(limit),
          total: disasters.length
        }
      });
    } catch (error) {
      res.status(500).json({
        success: false,
        error: error.message
      });
    }
  }

  async createDisaster(req, res) {
    try {
      const { name, latitude, longitude, radius, initialFunding } = req.body;
      
      // Create on blockchain first
      const result = await blockchainService.createDisasterZone(
        name,
        latitude,
        longitude,
        radius,
        initialFunding
      );
      
      // Save to database
      const disaster = await db.disasters.create({
        zoneId: result.zoneId,
        name,
        latitude,
        longitude,
        radius,
        initialFunding,
        txHash: result.txHash,
        status: 'active',
        createdBy: req.user.id
      });
      
      // Clear cache
      await cache.deletePattern('disasters:*');
      
      res.status(201).json({
        success: true,
        data: disaster
      });
    } catch (error) {
      res.status(400).json({
        success: false,
        error: error.message
      });
    }
  }

  async getDisasterStats(req, res) {
    try {
      const { id } = req.params;
      
      // Get blockchain stats
      const blockchainStats = await blockchainService.getDisasterZoneStats(id);
      
      // Get database stats
      const dbStats = await db.disasters.findByPk(id, {
        include: [
          { model: db.vendors, as: 'vendors' },
          { model: db.transactions, as: 'transactions' }
        ]
      });
      
      const stats = {
        ...blockchainStats,
        totalVendors: dbStats.vendors.length,
        totalTransactions: dbStats.transactions.length,
        avgTransactionValue: dbStats.transactions.reduce((sum, tx) => sum + tx.amount, 0) / dbStats.transactions.length || 0
      };
      
      res.json({
        success: true,
        data: stats
      });
    } catch (error) {
      res.status(500).json({
        success: false,
        error: error.message
      });
    }
  }
}

module.exports = new DisasterController();
```

### ðŸ”§ Task 2: Database & Storage (2 days)

#### PostgreSQL Schema
```sql
-- Database schema for disaster relief system
CREATE DATABASE disaster_relief;

-- Disasters table
CREATE TABLE disasters (
    id SERIAL PRIMARY KEY,
    zone_id INTEGER UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    latitude DECIMAL(10, 8) NOT NULL,
    longitude DECIMAL(11, 8) NOT NULL,
    radius INTEGER NOT NULL,
    initial_funding DECIMAL(20, 6) DEFAULT 0,
    current_funding DECIMAL(20, 6) DEFAULT 0,
    total_spent DECIMAL(20, 6) DEFAULT 0,
    status VARCHAR(50) DEFAULT 'active',
    tx_hash VARCHAR(66),
    created_by INTEGER REFERENCES users(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Users table
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    wallet_address VARCHAR(42) UNIQUE NOT NULL,
    role VARCHAR(50) DEFAULT 'user',
    email VARCHAR(255),
    name VARCHAR(255),
    verified BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Vendors table
CREATE TABLE vendors (
    id SERIAL PRIMARY KEY,
    wallet_address VARCHAR(42) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    location VARCHAR(255),
    disaster_zone_id INTEGER REFERENCES disasters(zone_id),
    verified BOOLEAN DEFAULT false,
    kyc_ipfs_hash VARCHAR(255),
    total_redeemed DECIMAL(20, 6) DEFAULT 0,
    transaction_count INTEGER DEFAULT 0,
    reputation_score DECIMAL(3, 2) DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Vouchers table
CREATE TABLE vouchers (
    id SERIAL PRIMARY KEY,
    voucher_id INTEGER UNIQUE NOT NULL,
    beneficiary VARCHAR(42) NOT NULL,
    disaster_zone_id INTEGER REFERENCES disasters(zone_id),
    amount DECIMAL(20, 6) NOT NULL,
    expiry_time TIMESTAMP NOT NULL,
    used BOOLEAN DEFAULT false,
    allowed_categories TEXT[], 
    tx_hash VARCHAR(66),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Transactions table
CREATE TABLE transactions (
    id SERIAL PRIMARY KEY,
    tx_hash VARCHAR(66) UNIQUE NOT NULL,
    voucher_id INTEGER REFERENCES vouchers(voucher_id),
    vendor_address VARCHAR(42) REFERENCES vendors(wallet_address),
    beneficiary VARCHAR(42),
    amount DECIMAL(20, 6) NOT NULL,
    category VARCHAR(100),
    ipfs_proof_hash VARCHAR(255),
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    block_number BIGINT,
    timestamp TIMESTAMP NOT NULL,
    status VARCHAR(50) DEFAULT 'confirmed'
);

-- Proof of aid table
CREATE TABLE proof_of_aid (
    id SERIAL PRIMARY KEY,
    proof_id INTEGER UNIQUE NOT NULL,
    transaction_id INTEGER REFERENCES transactions(id),
    ipfs_hash VARCHAR(255) NOT NULL,
    file_type VARCHAR(50),
    file_size INTEGER,
    metadata JSONB,
    verified BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Analytics table for caching
CREATE TABLE analytics_cache (
    id SERIAL PRIMARY KEY,
    cache_key VARCHAR(255) UNIQUE NOT NULL,
    data JSONB NOT NULL,
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for performance
CREATE INDEX idx_disasters_status ON disasters(status);
CREATE INDEX idx_disasters_created_at ON disasters(created_at);
CREATE INDEX idx_vendors_disaster_zone ON vendors(disaster_zone_id);
CREATE INDEX idx_transactions_timestamp ON transactions(timestamp);
CREATE INDEX idx_transactions_voucher ON transactions(voucher_id);
CREATE INDEX idx_proof_ipfs ON proof_of_aid(ipfs_hash);
```

#### Database Service Implementation
```javascript
// src/services/databaseService.js
const { Sequelize, DataTypes } = require('sequelize');

const sequelize = new Sequelize(process.env.DATABASE_URL, {
  dialect: 'postgres',
  logging: process.env.NODE_ENV === 'development' ? console.log : false,
  pool: {
    max: 20,
    min: 0,
    acquire: 30000,
    idle: 10000
  }
});

// Models
const Disaster = sequelize.define('Disaster', {
  zoneId: {
    type: DataTypes.INTEGER,
    unique: true,
    allowNull: false
  },
  name: {
    type: DataTypes.STRING,
    allowNull: false
  },
  latitude: {
    type: DataTypes.DECIMAL(10, 8),
    allowNull: false
  },
  longitude: {
    type: DataTypes.DECIMAL(11, 8), 
    allowNull: false
  },
  radius: {
    type: DataTypes.INTEGER,
    allowNull: false
  },
  initialFunding: {
    type: DataTypes.DECIMAL(20, 6),
    defaultValue: 0
  },
  currentFunding: {
    type: DataTypes.DECIMAL(20, 6),
    defaultValue: 0
  },
  totalSpent: {
    type: DataTypes.DECIMAL(20, 6),
    defaultValue: 0
  },
  status: {
    type: DataTypes.STRING(50),
    defaultValue: 'active'
  },
  txHash: DataTypes.STRING(66),
  createdBy: DataTypes.INTEGER
});

const User = sequelize.define('User', {
  walletAddress: {
    type: DataTypes.STRING(42),
    unique: true,
    allowNull: false
  },
  role: {
    type: DataTypes.STRING(50),
    defaultValue: 'user'
  },
  email: DataTypes.STRING,
  name: DataTypes.STRING,
  verified: {
    type: DataTypes.BOOLEAN,
    defaultValue: false
  }
});

const Vendor = sequelize.define('Vendor', {
  walletAddress: {
    type: DataTypes.STRING(42),
    unique: true,
    allowNull: false
  },
  name: {
    type: DataTypes.STRING,
    allowNull: false
  },
  location: DataTypes.STRING,
  disasterZoneId: {
    type: DataTypes.INTEGER,
    references: {
      model: Disaster,
      key: 'zoneId'
    }
  },
  verified: {
    type: DataTypes.BOOLEAN,
    defaultValue: false
  },
  kycIpfsHash: DataTypes.STRING,
  totalRedeemed: {
    type: DataTypes.DECIMAL(20, 6),
    defaultValue: 0
  },
  transactionCount: {
    type: DataTypes.INTEGER,
    defaultValue: 0
  },
  reputationScore: {
    type: DataTypes.DECIMAL(3, 2),
    defaultValue: 0
  }
});

// Associations
Disaster.hasMany(Vendor, { foreignKey: 'disasterZoneId', as: 'vendors' });
Vendor.belongsTo(Disaster, { foreignKey: 'disasterZoneId', as: 'disaster' });

module.exports = {
  sequelize,
  disasters: Disaster,
  users: User,
  vendors: Vendor,
  
  async initialize() {
    try {
      await sequelize.authenticate();
      console.log('âœ… Database connection established');
      
      if (process.env.NODE_ENV === 'development') {
        await sequelize.sync({ alter: true });
        console.log('âœ… Database tables synchronized');
      }
    } catch (error) {
      console.error('âŒ Database connection failed:', error);
      throw error;
    }
  }
};
```

#### Redis Caching Service
```javascript
// src/services/cacheService.js
const redis = require('redis');

class CacheService {
  constructor() {
    this.client = redis.createClient({
      url: process.env.REDIS_URL || 'redis://localhost:6379'
    });
    
    this.client.on('error', (err) => {
      console.error('Redis Client Error', err);
    });
    
    this.client.connect();
  }

  async get(key) {
    try {
      const value = await this.client.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  }

  async set(key, value, expiration = 3600) {
    try {
      await this.client.setEx(key, expiration, JSON.stringify(value));
      return true;
    } catch (error) {
      console.error('Cache set error:', error);
      return false;
    }
  }

  async delete(key) {
    try {
      await this.client.del(key);
      return true;
    } catch (error) {
      console.error('Cache delete error:', error);
      return false;
    }
  }

  async deletePattern(pattern) {
    try {
      const keys = await this.client.keys(pattern);
      if (keys.length > 0) {
        await this.client.del(keys);
      }
      return true;
    } catch (error) {
      console.error('Cache delete pattern error:', error);
      return false;
    }
  }

  async increment(key, value = 1) {
    try {
      return await this.client.incrBy(key, value);
    } catch (error) {
      console.error('Cache increment error:', error);
      return null;
    }
  }
}

module.exports = new CacheService();
```

### ðŸ”§ Task 3: Real-time Services (1-2 days)

#### WebSocket Server Implementation
```javascript
// src/services/websocketService.js
const WebSocket = require('ws');
const jwt = require('jsonwebtoken');

class WebSocketService {
  constructor(server) {
    this.wss = new WebSocket.Server({ 
      server,
      verifyClient: this.verifyClient.bind(this)
    });
    
    this.clients = new Map();
    
    this.wss.on('connection', this.handleConnection.bind(this));
  }

  verifyClient(info) {
    try {
      const token = new URL(info.req.url, 'http://localhost').searchParams.get('token');
      if (token) {
        const decoded = jwt.verify(token, process.env.JWT_SECRET);
        info.req.user = decoded;
        return true;
      }
      return false;
    } catch (error) {
      return false;
    }
  }

  handleConnection(ws, req) {
    const userId = req.user.id;
    this.clients.set(userId, ws);
    
    console.log(`âœ… WebSocket connected: User ${userId}`);
    
    ws.on('message', (message) => {
      try {
        const data = JSON.parse(message);
        this.handleMessage(userId, data);
      } catch (error) {
        console.error('WebSocket message error:', error);
      }
    });
    
    ws.on('close', () => {
      this.clients.delete(userId);
      console.log(`âŒ WebSocket disconnected: User ${userId}`);
    });
    
    // Send welcome message
    this.sendToUser(userId, {
      type: 'connected',
      message: 'Connected to disaster relief network',
      timestamp: new Date().toISOString()
    });
  }

  handleMessage(userId, data) {
    switch (data.type) {
      case 'subscribe_disaster':
        this.subscribeToDisaster(userId, data.disasterId);
        break;
      case 'subscribe_transactions':
        this.subscribeToTransactions(userId);
        break;
      case 'ping':
        this.sendToUser(userId, { type: 'pong', timestamp: new Date().toISOString() });
        break;
    }
  }

  subscribeToDisaster(userId, disasterId) {
    // Implementation for disaster-specific updates
    this.sendToUser(userId, {
      type: 'subscribed',
      disaster: disasterId,
      message: `Subscribed to disaster ${disasterId} updates`
    });
  }

  sendToUser(userId, data) {
    const ws = this.clients.get(userId);
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify(data));
    }
  }

  broadcast(data, filter = () => true) {
    this.clients.forEach((ws, userId) => {
      if (ws.readyState === WebSocket.OPEN && filter(userId)) {
        ws.send(JSON.stringify(data));
      }
    });
  }

  broadcastTransactionUpdate(transaction) {
    this.broadcast({
      type: 'transaction_update',
      data: transaction,
      timestamp: new Date().toISOString()
    });
  }

  broadcastDisasterUpdate(disaster) {
    this.broadcast({
      type: 'disaster_update', 
      data: disaster,
      timestamp: new Date().toISOString()
    });
  }
}

module.exports = WebSocketService;
```

#### Blockchain Event Listener
```javascript
// src/services/blockchainEventListener.js
const { ethers } = require('ethers');
const db = require('./databaseService');
const websocketService = require('./websocketService');
const notificationService = require('./notificationService');

class BlockchainEventListener {
  constructor() {
    this.provider = new ethers.providers.JsonRpcProvider(process.env.RPC_URL);
    this.contract = new ethers.Contract(
      process.env.DISASTER_RELIEF_CONTRACT,
      require('../abis/DisasterReliefSystem.json'),
      this.provider
    );
    
    this.setupEventListeners();
  }

  setupEventListeners() {
    // Listen for disaster zone creation
    this.contract.on('DisasterZoneCreated', async (zoneId, name, funding, event) => {
      try {
        const disaster = await db.disasters.findOne({ where: { zoneId: zoneId.toNumber() } });
        
        if (disaster) {
          disaster.currentFunding = ethers.utils.formatUnits(funding, 6);
          await disaster.save();
          
          // Broadcast update
          websocketService.broadcastDisasterUpdate({
            id: disaster.id,
            zoneId: zoneId.toNumber(),
            name,
            funding: ethers.utils.formatUnits(funding, 6),
            status: 'active'
          });
          
          // Send notifications
          await notificationService.sendDisasterAlert({
            type: 'disaster_created',
            disaster: disaster.name,
            funding: ethers.utils.formatUnits(funding, 6)
          });
        }
      } catch (error) {
        console.error('Error handling DisasterZoneCreated event:', error);
      }
    });

    // Listen for voucher redemptions
    this.contract.on('VoucherRedeemed', async (vendor, voucherId, amount, event) => {
      try {
        const transaction = await this.createTransactionRecord({
          txHash: event.transactionHash,
          voucherId: voucherId.toNumber(),
          vendorAddress: vendor,
          amount: ethers.utils.formatUnits(amount, 6),
          blockNumber: event.blockNumber,
          timestamp: new Date()
        });
        
        // Broadcast real-time update
        websocketService.broadcastTransactionUpdate({
          id: transaction.id,
          vendor,
          amount: ethers.utils.formatUnits(amount, 6),
          voucherId: voucherId.toNumber(),
          txHash: event.transactionHash
        });
        
        // Update vendor statistics
        await this.updateVendorStats(vendor, ethers.utils.formatUnits(amount, 6));
        
      } catch (error) {
        console.error('Error handling VoucherRedeemed event:', error);
      }
    });

    // Listen for proof of aid submissions
    this.contract.on('ProofOfAidSubmitted', async (proofId, voucherId, ipfsHash, event) => {
      try {
        await db.proofOfAid.create({
          proofId: proofId.toNumber(),
          voucherId: voucherId.toNumber(),
          ipfsHash,
          txHash: event.transactionHash,
          verified: false
        });
        
        console.log(`âœ… Proof of aid recorded: ${ipfsHash}`);
      } catch (error) {
        console.error('Error handling ProofOfAidSubmitted event:', error);
      }
    });
  }

  async createTransactionRecord(data) {
    return await db.transactions.create(data);
  }

  async updateVendorStats(vendorAddress, amount) {
    const vendor = await db.vendors.findOne({ where: { walletAddress: vendorAddress } });
    if (vendor) {
      vendor.totalRedeemed = parseFloat(vendor.totalRedeemed) + parseFloat(amount);
      vendor.transactionCount += 1;
      await vendor.save();
    }
  }

  start() {
    console.log('ðŸŽ§ Blockchain event listener started');
    console.log(`ðŸ“¡ Listening to contract: ${process.env.DISASTER_RELIEF_CONTRACT}`);
  }

  stop() {
    this.contract.removeAllListeners();
    console.log('ðŸ›‘ Blockchain event listener stopped');
  }
}

module.exports = BlockchainEventListener;
```

---

## ðŸŽ¯ PHASE 4: Advanced Features & Integrations  
**Duration**: 3-5 days | **Priority**: Medium | **Timeline**: Aug 24-29, 2025

### ðŸ”§ Task 1: Block Explorer Integration (1 day)

#### Routescan Integration Setup
```javascript
// src/services/explorerService.js
const axios = require('axios');

class ExplorerService {
  constructor() {
    this.explorerUrl = process.env.SUBNET_EXPLORER_URL || 'https://subnets.avax.network/disaster-relief';
    this.apiUrl = `${this.explorerUrl}/api`;
  }

  async getTransactionDetails(txHash) {
    try {
      const response = await axios.get(`${this.apiUrl}/tx/${txHash}`);
      return response.data;
    } catch (error) {
      console.error('Explorer API error:', error);
      return null;
    }
  }

  async getAddressTransactions(address, page = 1, limit = 10) {
    try {
      const response = await axios.get(`${this.apiUrl}/address/${address}/transactions`, {
        params: { page, limit }
      });
      return response.data;
    } catch (error) {
      console.error('Explorer API error:', error);
      return [];
    }
  }

  async getContractInfo(contractAddress) {
    try {
      const response = await axios.get(`${this.apiUrl}/contract/${contractAddress}`);
      return response.data;
    } catch (error) {
      console.error('Explorer API error:', error);
      return null;
    }
  }

  getTransactionUrl(txHash) {
    return `${this.explorerUrl}/tx/${txHash}`;
  }

  getAddressUrl(address) {
    return `${this.explorerUrl}/address/${address}`;
  }
}

module.exports = new ExplorerService();
```

### ðŸ”§ Task 2: Oracle & Data Feeds (2 days)

#### Chainlink Price Feeds Integration
```solidity
// contracts/src/PriceFeed.sol
pragma solidity ^0.8.19;

import "@chainlink/contracts/src/v0.8/interfaces/AggregatorV3Interface.sol";

contract PriceFeed {
    AggregatorV3Interface internal priceFeed;
    
    // Fuji testnet AVAX/USD: 0x5498BB568091b3b4C661D0C35BD1Eb3fE1C59f67
    constructor() {
        priceFeed = AggregatorV3Interface(0x5498BB568091b3b4C661D0C35BD1Eb3fE1C59f67);
    }
    
    function getLatestPrice() public view returns (int) {
        (,int price,,,) = priceFeed.latestRoundData();
        return price;
    }
    
    function convertUSDToAVAX(uint256 usdAmount) public view returns (uint256) {
        int price = getLatestPrice();
        require(price > 0, "Invalid price");
        
        // Price is in 8 decimals, convert to 18 decimals
        uint256 avaxPrice = uint256(price) * 1e10;
        return (usdAmount * 1e18) / avaxPrice;
    }
}
```

### ðŸ”§ Task 3: Security & Auditing (2 days)

#### Automated Security Scanning
```javascript
// scripts/security-audit.js
const { exec } = require('child_process');
const fs = require('fs');

class SecurityAudit {
  async runSlither() {
    return new Promise((resolve, reject) => {
      exec('slither contracts/src --json slither-report.json', (error, stdout, stderr) => {
        if (error) {
          console.error('Slither error:', error);
          reject(error);
          return;
        }
        
        const report = JSON.parse(fs.readFileSync('slither-report.json', 'utf8'));
        const criticalIssues = report.results.detectors.filter(d => d.impact === 'High');
        
        resolve({
          total: report.results.detectors.length,
          critical: criticalIssues.length,
          issues: criticalIssues
        });
      });
    });
  }

  async runMythril() {
    return new Promise((resolve, reject) => {
      exec('myth analyze contracts/src/DisasterReliefSystem.sol --solv 0.8.19', (error, stdout, stderr) => {
        if (error) {
          console.error('Mythril error:', error);
          reject(error);
          return;
        }
        
        resolve(stdout);
      });
    });
  }

  async generateReport() {
    try {
      console.log('ðŸ” Running security audit...');
      
      const slitherResults = await this.runSlither();
      const mythrilResults = await this.runMythril();
      
      const report = {
        timestamp: new Date().toISOString(),
        slither: slitherResults,
        mythril: mythrilResults,
        recommendations: this.generateRecommendations(slitherResults)
      };
      
      fs.writeFileSync('security-audit-report.json', JSON.stringify(report, null, 2));
      console.log('âœ… Security audit completed');
      
      return report;
    } catch (error) {
      console.error('âŒ Security audit failed:', error);
      throw error;
    }
  }

  generateRecommendations(slitherResults) {
    const recommendations = [];
    
    if (slitherResults.critical > 0) {
      recommendations.push('ðŸš¨ Critical security issues found - address immediately');
    }
    
    recommendations.push('âœ… Implement multi-signature for admin functions');
    recommendations.push('âœ… Add emergency pause mechanism');
    recommendations.push('âœ… Implement rate limiting for sensitive operations');
    
    return recommendations;
  }
}

// Run audit
const audit = new SecurityAudit();
audit.generateReport().catch(console.error);
```

---

## ðŸŽ¯ PHASE 5: Production Deployment & Optimization
**Duration**: 2-3 days | **Priority**: High | **Timeline**: Aug 30 - Sep 2, 2025

### ðŸ”§ Task 1: Production Deployment (1 day)

#### Docker Configuration
```dockerfile
# Dockerfile.frontend
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

```dockerfile  
# Dockerfile.backend
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3000
CMD ["node", "server.js"]
```

#### Docker Compose for Production
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
      - "443:443"
    environment:
      - NODE_ENV=production
    volumes:
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - backend

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
    depends_on:
      - postgres
      - redis

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: disaster_relief
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend

volumes:
  postgres_data:
  redis_data:
```

#### CI/CD Pipeline (GitHub Actions)
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: |
          cd frontend && npm ci
          cd ../backend && npm ci
      
      - name: Run tests
        run: |
          cd frontend && npm test
          cd ../backend && npm test
      
      - name: Build frontend
        run: cd frontend && npm run build

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to production server
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /opt/disaster-relief
            git pull origin main
            docker-compose -f docker-compose.prod.yml down
            docker-compose -f docker-compose.prod.yml up -d --build
            docker system prune -f
```

### ðŸ”§ Task 2: Performance Optimization (1 day)

#### Frontend Optimization
```javascript
// vite.config.js - Production optimizations
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
import { VitePWA } from 'vite-plugin-pwa'

export default defineConfig({
  plugins: [
    react(),
    VitePWA({
      registerType: 'autoUpdate',
      workbox: {
        globPatterns: ['**/*.{js,css,html,ico,png,svg,woff2}'],
        runtimeCaching: [
          {
            urlPattern: /^https:\/\/api\.avax-test\.network\/.*/i,
            handler: 'CacheFirst',
            options: {
              cacheName: 'avalanche-api-cache',
              expiration: {
                maxEntries: 50,
                maxAgeSeconds: 60 * 60 * 24 // 24 hours
              }
            }
          }
        ]
      }
    })
  ],
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['react', 'react-dom'],
          web3: ['ethers'],
          ui: ['framer-motion', 'lucide-react']
        }
      }
    },
    chunkSizeWarningLimit: 1000
  }
})
```

### ðŸ”§ Task 3: Documentation & Testing (1 day)

#### API Documentation (OpenAPI/Swagger)
```yaml
# docs/api-spec.yml
openapi: 3.0.0
info:
  title: Disaster Relief API
  description: API for Avalanche-powered disaster relief network
  version: 1.0.0
  
servers:
  - url: https://api.disaster-relief.network/v1
    description: Production server
    
paths:
  /disasters:
    get:
      summary: Get all disasters
      parameters:
        - name: page
          in: query
          schema:
            type: integer
            default: 1
        - name: limit
          in: query
          schema:
            type: integer
            default: 10
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  success:
                    type: boolean
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/Disaster'
                      
    post:
      summary: Create new disaster
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateDisasterRequest'
      responses:
        '201':
          description: Disaster created successfully

components:
  schemas:
    Disaster:
      type: object
      properties:
        id:
          type: integer
        zoneId:
          type: integer
        name:
          type: string
        latitude:
          type: number
        longitude:
          type: number
        status:
          type: string
          enum: [active, inactive, completed]
        
    CreateDisasterRequest:
      type: object
      required:
        - name
        - latitude
        - longitude
        - radius
      properties:
        name:
          type: string
        latitude:
          type: number
        longitude:
          type: number
        radius:
          type: integer
        initialFunding:
          type: number
          
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
```

---

## ðŸ“Š Implementation Timeline Summary

| Phase | Duration | Priority | Key Deliverables |
|-------|----------|----------|------------------|
| **PHASE 2** | 5-7 Hours | **CRITICAL** | âœ… Avalanche subnet deployment<br>âœ… Smart contracts deployed<br>âœ… Frontend-blockchain integration |
| **PHASE 3** | 4-6 Hours | **HIGH** | âœ… Complete REST API<br>âœ… Database with caching<br>âœ… Real-time monitoring |
| **PHASE 4** | 3-5 Hours | **MEDIUM** | âœ… Block explorer integration<br>âœ… Oracle data feeds<br>âœ… Security audits |
| **PHASE 5** | 2-3 Hours | **HIGH** | âœ… Production deployment<br>âœ… Performance optimization<br>âœ… Documentation |

**Total Duration**: 14-21 Hours  

---

## ðŸš¨ Critical Success Factors

### 1. **Immediate Priorities (Next 48 Hours)**
- âœ… Install and configure Avalanche CLI
- âœ… Create and deploy disaster relief subnet
- âœ… Deploy smart contracts to testnet
- âœ… Update frontend with contract addresses

### 2. **Weekly Milestones**
- **Week 1**: Complete blockchain infrastructure (PHASE 2)
- **Week 2**: Backend services and APIs (PHASE 3)  
- **Week 3**: Advanced features and production deployment (PHASE 4-5)

### 3. **Risk Mitigation**
- **Technical Risks**: Maintain comprehensive testing throughout
- **Timeline Risks**: Focus on critical path items first
- **Integration Risks**: Incremental integration and testing

This roadmap transforms your excellent PHASE 1 foundation into a complete, production-ready disaster relief system on Avalanche. Each phase builds upon the previous work while delivering tangible value at every step.